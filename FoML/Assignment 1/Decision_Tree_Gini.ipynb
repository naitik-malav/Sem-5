{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f6de81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "myname = \"Naitik-Malav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5214c820",
   "metadata": {},
   "source": [
    "# Decision Tree Implementation using Gini Index\n",
    "Decision tree using binary univariate split, gini index and information gain.\n",
    "### Learn\n",
    "learn function of class DecisionTree is used to build the decision tree by calling build_decision_tree function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db1ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    tree = {}\n",
    "    \n",
    "    def learn(self, data_set):\n",
    "        # implement this function\n",
    "        self.tree = build_decision_tree(data_set)\n",
    "        return self.tree "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663488fe",
   "metadata": {},
   "source": [
    "### build_decision_tree\n",
    "Every Node of the decision tree is a question and based on a question we have two child nodes. \n",
    "First we have to calculate the information gain, so I have calculated using gini index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc896a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decision_tree(data_set):\n",
    "    question, info_gain = best_split(data_set)\n",
    "\n",
    "    if info_gain != 0:\n",
    "        trueRows, falseRows = partitioning(data_set, question)\n",
    "\n",
    "        #recursive call to each rows\n",
    "        trueBranch = build_decision_tree(trueRows)\n",
    "        falseBranch = build_decision_tree(falseRows)\n",
    "\n",
    "        # returns a Question-Decision node\n",
    "        return Decision_Node(question, trueBranch, falseBranch)\n",
    "\n",
    "    \n",
    "    # 0 information gain means it's a leaf node\n",
    "    return Leaf(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad00c4c",
   "metadata": {},
   "source": [
    "### best_split\n",
    "Iterating over every value and we will calculate the information index and highest information index will given more preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0877a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(data_set):\n",
    "    \n",
    "    #best information gain and question of the node\n",
    "    best_question = None \n",
    "    best_information_gain = 0  \n",
    "    \n",
    "    uncertainty = gini_index(data_set)\n",
    "    \n",
    "    for column in range(len(data_set[0])-1): \n",
    "        \n",
    "        values = set()\n",
    "        for row in data_set:\n",
    "            values.add(row[column])\n",
    "            \n",
    "        for value in values: \n",
    "            question = Question(column, value)\n",
    "            trueRows, falseRows = partitioning(data_set, question)\n",
    "\n",
    "            if len(falseRows)==0:\n",
    "                continue\n",
    "            if len(trueRows)==0:\n",
    "                continue\n",
    "\n",
    "            info_gain = information_gain(trueRows, falseRows, uncertainty)\n",
    "\n",
    "            if best_information_gain <= info_gain:\n",
    "                best_information_gain = info_gain\n",
    "                best_question = question\n",
    "\n",
    "    return best_question, best_information_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa604e14",
   "metadata": {},
   "source": [
    "### Question\n",
    "It is used to partition the dataset. \n",
    "It stores the column number and column value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b45ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question:\n",
    "    def __init__(self, x, y):\n",
    "        self.column, self.value = x, y\n",
    "\n",
    "    # Compares the feature value in an example to the feature value in this question.\n",
    "    def match(self, example):\n",
    "        x = example[self.column]\n",
    "        if isinstance(x, int) or isinstance(x, float) == True:\n",
    "            return x >= self.value\n",
    "        else:\n",
    "            return x == self.value\n",
    "\n",
    "    # used to print the question of the tree\n",
    "    def __repr__(self):\n",
    "        return utility(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15019d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility(Node):\n",
    "    condition = \"==\"\n",
    "    if isinstance(Node.value, int) or isinstance(Node.value, float) == True:\n",
    "        condition = \">=\"\n",
    "    return \"Is %s %s %s?\" % (header[Node.column], condition, str(Node.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136c62c2",
   "metadata": {},
   "source": [
    "### partitioning the dataset\n",
    "If a row matches with the question then add it to trueRows else add it to falseRows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e3fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partitioning(data_set, question):\n",
    "    trueRows = []\n",
    "    falseRows = []\n",
    "    \n",
    "    for row in data_set:\n",
    "        if question.match(row)==False:\n",
    "            falseRows.append(row)\n",
    "        else:\n",
    "            trueRows.append(row)\n",
    "    return trueRows, falseRows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c44cfed",
   "metadata": {},
   "source": [
    "### Decision_Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4d1635",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Node:\n",
    "    def __init__(self, question, trueBranch, falseBranch):\n",
    "        self.question, self.true, self.false = question, trueBranch, falseBranch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3bc7c5",
   "metadata": {},
   "source": [
    "### Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b776754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(left, right, current):\n",
    "    \n",
    "    p = float(len(left)) / (len(left) + len(right))\n",
    "    return current - (p*gini_index(left) + (1-p)*gini_index(right))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8f6441",
   "metadata": {},
   "source": [
    "### Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ed8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index(data_set):\n",
    "    labels = Label_Count(data_set)\n",
    "    impurity = 1\n",
    "    for label in labels:\n",
    "        probability = labels[label]/float(len(data_set))\n",
    "        impurity = impurity - (probability*probability)\n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7db7ddf",
   "metadata": {},
   "source": [
    "# Classification\n",
    "Classifying the test_set using the decision tree (d_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32571b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(instance, Node):\n",
    "    #Leaf Node\n",
    "    if isinstance(Node, Leaf):\n",
    "        return Node.predictions\n",
    "\n",
    "    #recursive call to 'true' side and 'false' side\n",
    "    if Node.question.match(instance):\n",
    "        return classify(instance, Node.true)\n",
    "    else:\n",
    "        return classify(instance, Node.false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b2cbf3",
   "metadata": {},
   "source": [
    "### Leaf Node\n",
    "A Leaf node holds a dictionary of label as key and number of times it appears in the rows from the training data that reach this leaf. That is data of the subset present at leaf node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c06ce3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    \n",
    "    def __init__(self, rows):\n",
    "        self.predictions = Label_Count(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1c3a85",
   "metadata": {},
   "source": [
    "### Label_Count\n",
    "Count the number of each type of label in a dataset and returns the dictionary of label as a key and count as a value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ebd9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Label_Count(rows):\n",
    "    counts = {}  # a dictionary of label -> count.\n",
    "    for row in rows:\n",
    "        # in our dataset the label is always the last column\n",
    "        label = row[-1]\n",
    "        if label not in counts:\n",
    "            counts[label] = 0\n",
    "        counts[label] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390be29b",
   "metadata": {},
   "source": [
    "### 10-Fold Cross Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f24de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_split(data_set, folds=10):\n",
    "    dataset_split = []\n",
    "    dataset_copy = list(data_set)\n",
    "    size = int(len(data_set) / folds)\n",
    "    \n",
    "    for i in range(folds):\n",
    "        fold = list()\n",
    "        while len(fold) < size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    \n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6826c24",
   "metadata": {},
   "source": [
    "### utility function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c4893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_decision_tree():\n",
    "\n",
    "    # Loading data set\n",
    "    with open(\"wine-dataset.csv\") as f:\n",
    "        next(f, None)\n",
    "        data = [line for line in csv.reader(f, delimiter=\",\")]    #data_set is a numpy array\n",
    "    print(\"Number of records: %d\" % len(data))\n",
    "\n",
    "    \n",
    "    f = open(myname+\"resultg.txt\", \"w\")\n",
    "    #10-fold cross validation\n",
    "#     K = 10\n",
    "#     training_set = [x for i, x in enumerate(data) if i % K != 9]\n",
    "#     test_set = [x for i, x in enumerate(data) if i % K == 9]\n",
    "\n",
    "#     print(test_set)\n",
    "    \n",
    "    accuracies = []\n",
    "    folds = cross_validation_split(data)\n",
    "    \n",
    "    for i in range(len(folds)):\n",
    "        training_set = []\n",
    "        test_set = []\n",
    "        for j in range(len(folds)):\n",
    "            if i==j:\n",
    "                test_set = folds[j]\n",
    "            else:\n",
    "                for k in range(len(folds[j])):\n",
    "                    training_set.append(folds[j][k])\n",
    "        \n",
    "        #print(training_set)\n",
    "        # Construct a tree using training set\n",
    "        obj = DecisionTree()\n",
    "        d_tree = obj.learn( training_set )\n",
    "        \n",
    "\n",
    "        # Classify the test set using the tree we just constructed\n",
    "        # I have implemented classify seperately or you can say I have done classification implementation outside of the class\n",
    "        results = []     \n",
    "        for instance in test_set:\n",
    "            #print(\"hello\", instance[:-1])\n",
    "            #print(classify(instance[:-1], my_tree ))\n",
    "            #print(list(classify(instance[:-1], my_tree ).keys())[0])\n",
    "            result = list((classify(instance[:-1], d_tree)).keys())[0]    #stores the count of (total positive + total negative)\n",
    "            results.append( result == instance[-1])\n",
    "\n",
    "        # Calculating Accuracy\n",
    "        accuracy = float(results.count(True))/float(len(results))\n",
    "        \n",
    "        #print(\"accuracy: %.4f\" % accuracy)\n",
    "        f.write(\"accuracy: %.4f\" % accuracy)\n",
    "        f.write(\"\\n\")\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        \n",
    "    avg_accuracy = 0\n",
    "    \n",
    "    for x in accuracies:\n",
    "        avg_accuracy += x\n",
    "    \n",
    "    avg_accuracy = float(avg_accuracy / float(len(accuracies)))\n",
    "    \n",
    "    print(\"Average Accuracy: %.4f\" % avg_accuracy)\n",
    "    f.write(\"Average Accuracy: %.4f\" % avg_accuracy)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac272bb1",
   "metadata": {},
   "source": [
    "### main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c965f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_decision_tree()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
